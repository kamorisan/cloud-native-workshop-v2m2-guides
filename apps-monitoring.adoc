= Lab3 - Application Monitoring
:experimental:

前回のラボでは、Quarkus フレームワークを使った CodeReady Workspaces を使って、クラウドネイティブアプリをデバッグしてエラーを素早く修正する方法を学び、開発者の喜びのための Quarkus の力を垣間見ることができました。

クラウドネイティブ・アプリケーションが急速に開発されているため、本番環境での分散アーキテクチャは、ネットワークと観測性という2つの分野で最終的に複雑になるからです。後日、service mesh を使用してアプリケーションをより良く管理・監視する方法を探ります。

このラボでは、 https://www.jaegertracing.io/[Jaeger^] と https://prometheus.io/[Prometheus^] を使用して coolstore アプリケーションを監視します。

image::quarkus-jaeger-prometheus.png[logo, 700]

*Jaeger* は、以下のようなマイクロサービスベースの分散システムを監視し、トラブルシューティングを行うためのオープンソースの分散トレースツールです。

* 分散型トランザクションの監視 (Distributed context propagation)
* 分散型トランザクションの監視 (Distributed transaction monitoring)
* 根本原因分析 (Root cause analysis)
* サービス依存性分析 (Service dependency analysis)
* パフォーマンスとレイテンシの最適化 (Performance and latency optimization)

*Prometheus* は、オープンソースのシステム監視およびアラートツールで、以下のような任意の数値時系列の記録に適合しています。

* メトリック名とキー/値のペアによる多次元時系列データ (Multi-dimensional time series data by metric name and key/value pairs)
* 分散型ストレージに依存しない (No reliance on distributed storage)
* HTTPを利用した時系列コレクション (Time series collection over HTTP)
* 中間ゲートウェイを介して時系列をプッシュすることができます (Pushing time series is supported via an intermediary gateway)
* サービスの発見または静的な設定 (Service discovery or static configuration)

==== 1. Create OpenShift Project

このステップでは、CoolStore アプリケーション用の新しい監視ツールを展開します。
そのため、monolith や以前に作成した他のマイクロサービスとは別のプロジェクトを作成しておきます。

{{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-coolstore-dev[Topology View^] に戻り、プロジェクトのドロップダウンをクリックして、Create Project を選択します。 

image::create_project.png[create_dialog, 700]

フィールドに以下の内容を入力し、 *Create* をクリックします。

* Name: `{{USER_ID}}-monitoring`
* Display Name: `{{USER_ID}} CoolStore App Monitoring Tools`
* Description: 空欄にする

image::create_monitoring_dialog.png[create_dialog, 700]

==== 2. Deploy Jaeger to OpenShift

新しいプロジェクトで `+Add` をクリックし、 *From Catalog* を選択します。

jaeger サーバーを導入するには、右上の `+` アイコンをクリックします。

image::plus-icon.png[serverless, 500]

以下の _Service_ を `YAML` エディタでコピーし、 *Create* をクリックします。

[source,yaml,role="copypaste"]
----
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: jaeger-all-in-one-inmemory
  namespace: {{ USER_ID }}-monitoring
----

{{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-monitoring[Topology View^] では、Jaegerがデプロイされているのが確認できます。

image::jaeger_top.png[create_dialog, 500]

==== 4. Observe Jaeger UI

デプロイが完了したら（紺色の丸印！）、 https://jaeger-all-in-one-inmemory-{{USER_ID}}-monitoring.{{ ROUTE_SUBDOMAIN}}[Jaeger UI^] を開きます。

これは Jaeger の UI です。今のところ監視しているアプリがないので割と使い勝手が悪いように見えますが、心配しないしてください！
次のステップではトレースデータを活用していきます。

image::jaeger-ui.png[jaeger_ui, 700]

==== 5. Utilizing Opentracing with Inventory (Quarkus)

クラウドネイティブアプリケーションの一部として Quarkus で書かれたインベントリサービスを呼び出す、 Spring Boot で書かれたカタログサービスがあります。これらのアプリケーションは、 Jaeger を使って簡単にトレースすることができます。

このステップでは、 *smallrye-opentracing* を使用するためのインベントリアプリケーションに Quarkus の拡張機能を追加します。以下のコマンドを実行して、 CodeReady Workspaces Terminal 経由でトレース拡張機能を追加します。

[source,sh,role="copypaste"]
----
mvn quarkus:add-extension -Dextensions="smallrye-opentracing" -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m2-labs/inventory
----

下記を見てください。

[source,console]
----
✅ Adding extension io.quarkus:quarkus-smallrye-opentracing
----

それから `BUILD SUCCESS`。
これにより、インベントリマイクロサービスのために拡張機能の依存関係が `pom.xml` に追加されることが保証されます。

[NOTE]
====
https://vertx.io/[Vert.x^] 、 http://camel.apache.org/[Apache Camel^] 、 http://infinispan.org/[Infinispan^] 、Spring DI互換性（ `@Autowired` など）など、人気のあるフレームワークの Quarkusの https://quarkus.io/extensions/[拡張機能^] は他にもたくさんあります。
====

==== 6. Create the configuration

このステップを始める前に、 {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-monitoring[Topology View^] にアクセスして *jaeger-collector* サービスを確認し、_jaeger_ デプロイメントをクリックして _Resources_ タブを選択して、 Jaeger によって公開されているサービスを表示します。

image::jaeger-services.png[create_dialog, 700]

ポート `14268` で `http-c-binary-trft` サービスを使用してトレースを報告するようにアプリを設定します。

workspace `cloud-native-workshop-v2m2-lab` の下にある `inventory` プロジェクトで、 `src/main/resources/application.properties` ファイルを開き、 CodeReady Workspaces Terminal を通じて以下の設定を追加します。

[source,properties,role="copypaste"]
----
# Jaeger configuration
%prod.quarkus.jaeger.service-name=inventory
%prod.quarkus.jaeger.sampler-type=const
%prod.quarkus.jaeger.sampler-param=1
%prod.quarkus.jaeger.endpoint=http://jaeger-all-in-one-inmemory-collector.{{ USER_ID }}-monitoring.svc.cluster.local:14268/api/traces
----

環境変数やJVMのプロパティを使って設定を指定することもできます。 https://www.jaegertracing.io/docs/1.12/client-features/[Jaeger Features^] を参照してください。

[NOTE]
====
もし `quarkus.jaeger.service-name` プロパティ (または環境変数 `JAEGER_SERVICE_NAME`) が指定されていない場合は、`no-op` トレーサーが設定され、バックエンドにトレースデータが報告されません。
====

[NOTE]
====
アプリケーションには特定のトレースコードは含まれていません。デフォルトでは、アプリに送信された RESTful リクエストは、MicroProfile Tracing のおかげで *コードの変更を必要とせず* にトレースされます。また、トレース情報を強化し、他のメソッドやクラスを手動でトレースすることも可能です。これについての詳細は、 https://github.com/eclipse/microprofile-opentracing/blob/master/spec/src/main/asciidoc/microprofile-opentracing.asciidoc[MicroProfile OpenTracing specification^] 仕様を参照してください。
====

==== 7. Re-Deploy to OpenShift

ターミナルを介してインベントリアプリケーションをリパッケージし、再デプロイします。

[source,sh,role="copypaste"]
----
oc project {{ USER_ID }}-inventory && \
mvn package -DskipTests -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m2-labs/inventory
----

コンソールと {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-inventory[Inventory Topology View^] で、再構築と再展開が完了するのを待ちます。

==== 8. Observing Jaeger Tracing

ネットワークとデータトランザクションをトレースするために、 CodeReady Workspaces Terminal を介して *curl* コマンドを使用してInventoryサービスを呼び出します。

トレースを生成するには、インベントリを10回呼び出します。

[source,sh,role="copypaste"]
----
URL="http://$(oc get route -n {{ USER_ID }}-inventory inventory -o jsonpath={% raw %}"{.spec.host}"{% endraw %})"

for i in $(seq 1 10) ; do
  curl -s $URL/services/inventory/165613
  sleep .2
done
----

http://jaeger-query-{{USER_ID}}-monitoring.{{ ROUTE_SUBDOMAIN}}[Jaeger UI^] をリロードすると、新しい `inventory` サービスが Jaeger 自身のサービスと並んで表示されることに気づくでしょう。

image::jaeger-2-services.png[jaeger_ui, 700]

`inventory` サービスを選択し、 *Find Traces* をクリックして、グラフ上の最初のトレースを観察します。

image::jaeger-reload.png[jaeger_ui, 700]

単一の *Span* をクリックすると、操作名、操作の開始時刻、期間を持つ論理的な作業単位が Jaeger に表示されます。 Span は、因果関係をモデル化するために入れ子にしたり、順序をつけたりすることができます。

image::jaeger-span.png[jaeger_ui, 700]

アプリケーションがより複雑になり、多くのマイクロサービスが互いに呼び合うようになると、これらの Span やトレースはより複雑になりますが、アプリの問題点も明らかになります。

==== 9. Deploy Prometheus and Grafana to OpenShift

OpenShift Container Platformは、 https://prometheus.io[Prometheus] オープンソースプロジェクトとその広範なエコシステムをベースにした、構成済みで自己更新型の監視スタックを搭載して提供されます。クラスタコンポーネントの監視を提供し、発生した問題をクラスタ管理者に即座に通知する一連のアラートと一連の https://grafana.com/[Grafana] ダッシュボードを搭載しています。

image::monitoring-diagram.png[Prometheus, 700]

ただし、インベントリとカタログアプリケーションのサービスメトリクスをスクレイプするために、カスタムの *Prometheus* をデプロイします。そして、そのメトリクスデータを *Grafana* ダッシュボードを使って可視化していきます。

{{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-monitoring[Monitoring Topology View^] で、 `+Add` をクリックし、 *Container Image* を選択します。

image::add-to-project.png[Prometheus, 800]

以下の項目を記入してください。

* *Image Name*: `prom/prometheus:latest`
* *Application Name*: `prometheus-app`
* *Name*: `prometheus`

*Enter* を押すと、30秒後に *緑色のチェック付き* アイコンと *Validated* が表示されます。

残りはそのままにして、 *Create* をクリックします。

image::search-prometheus-image.png[Prometheus, 700]

Topology view では、 prometheus が回転しているのがわかります。それが完了したら、矢印をクリックして prometheus query UI にアクセスします。

image::prometheus-route.png[Prometheus, 700]

これは Prometheus Web UI をロードするはずです（これは後で使います）。

image::prometheus-webui.png[Prometheus, 700]

==== Deploy Grafana

先ほどと同じ手順で行います。 {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-monitoring[Monitoring Topology View^] で、 `+Add` をクリックして、 *Container Image* ,を選択し、フィールドに記入します。

* *Image Name*: `grafana/grafana:latest`
* *Application*: `grafana-app`
* *Name*: `grafana`

image名の横にある "虫眼鏡" の検索アイコンをクリックして、image が存在することを確認してください。

*Enter* を押すと、30秒後に *緑色のチェック付き* アイコンと *Validated* が表示されます。

残りはそのままにして、 *Create* をクリックします。

image::search-grafana-image.png[Grafana, 700]

Topology view では、 Grafana が回転しているのがわかります。それが完了したら、矢印をクリックして Grafana UI にアクセスします。

image::grafana-route.png[Prometheus, 700]

これは Grafana Web UI をロードする必要があります。

image::grafana-login.png[Grafana, 700]

以下の値を使用して Grafana Web UI にログインします。

* Username: `admin`
* Password: `admin`

新しいパスワードを *スキップ* して下さい。(または覚えている他のものに変更)

このように Grafana のランディングページが表示されます。

image::grafana-webui.png[Grafana, 700]

==== 10. Add a data source to Grafana

Add data source をクリックし、データソースのタイプとして *Prometheus* を選択します。

image::grafana-datasource-types.png[Grafana, 700]

以下の値を記入してください。

* *URL*: `http://prometheus.{{USER_ID}}-monitoring:9090`

*Save & Test* をクリックして、成功のメッセージが表示されたことを確認します。

image::grafana-ds-success.png[Grafana, 300]

この時点で、 Granana は、監視しているアプリケーションから収集したメトリクスを Prometheus から引き出すように設定されています。

==== 11. Utilize metrics specification for Inventory Microservice

このステップでは、 _Inventory(Quarkus)_ アプリケーションが *SmallRye Metrics extension* を通じて MicroProfile Metrics 仕様を利用する方法を学びます。 _MicroProfile Metrics_ を使用すると、アプリケーション内で何が起こっているかについての洞察を提供する様々なメトリクスや統計情報を収集することができます。

メトリクスは、JSON 形式または *OpenMetrics* 形式を使用してリモートで読み込むことができます。
_Prometheus_のような追加ツールで処理し、分析や可視化のために保存することができるようにします。

CodeReady ターミナルで以下のコマンドを使用して、 _smallrye-metrics_ を使用するために必要な Quarkus の拡張機能を Inventory アプリケーションに追加します。

[source,sh,role="copypaste"]
----
mvn quarkus:add-extension -Dextensions="metrics" -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m2-labs/inventory
----

出力を確認してみてください。

[source,console]
----
✅ Adding extension io.quarkus:quarkus-smallrye-metrics
----

目的のメトリクスが時間の経過とともに計算され、 _Prometheus_ や _Grafana_ で処理するためにエクスポートできるように、いくつかのアノテーションを追加してみましょう。

集めようとしているメトリクスは、以下のようなものです。

* *performedChecksAll*: _getAll()_ が何回実行されたかを表すカウンタ。
* *checksTimerAll*: _getAll()_ メソッドを実行するのにかかる時間の目安。
* *performedChecksAvail*: _getAvailability()_ が何回呼ばれたかを表すカウンタ
* *checksTimerAvail*: _getAvailability()_ メソッドを実行するのにかかる時間の目安。

In the _cloud-native-workshop-v2m2-labs/inventory_ project, open `src/main/java/com/redhat/coolstore/InventoryResource.java`. Replace the two methods _getAll()_ and
_getAvailability()_ with the below code which adds several annotations for custom metrics (*@Counted*, *@Timed*):

[source,java,role="copypaste"]
----
    @GET
    @Counted(name = "performedChecksAll", description = "How many getAll() have been performed.")
    @Timed(name = "checksTimerAll", description = "A measure of how long it takes to perform the getAll().", unit = MetricUnits.MILLISECONDS)
    public List<Inventory> getAll() {
        return Inventory.listAll();
    }

    @GET
    @Counted(name = "performedChecksAvail", description = "How many getAvailability() have been performed.")
    @Timed(name = "checksTimerAvail", description = "A measure of how long it takes to perform the getAvailability().", unit = MetricUnits.MILLISECONDS)
    @Path("{itemId}")
    public List<Inventory> getAvailability(@PathParam String itemId) {
        return Inventory.<Inventory>streamAll()
        .filter(p -> p.itemId.equals(itemId))
        .collect(Collectors.toList());
    }
----

Add the necessary imports at the top:

[source,java,role="copypaste"]
----
import org.eclipse.microprofile.metrics.MetricUnits;
import org.eclipse.microprofile.metrics.annotation.Counted;
import org.eclipse.microprofile.metrics.annotation.Timed;
----

==== 12. Redeploy to OpenShift

Repackage and redeploy the inventory application:

[source,sh,role="copypaste"]
----
oc project {{ USER_ID }}-inventory && \
mvn clean package -DskipTests -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m2-labs/inventory
----

You should get `BUILD SUCCESS` and then the application should be re-deployed. Watch the {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-inventory[Inventory Topology View^] until the app is re-deployed.

Once it's done you should be able to see the raw metrics exposed by the app with this command in a Terminal:

[source,sh,role="copypaste"]
----
curl http://inventory-{{USER_ID}}-inventory.{{ ROUTE_SUBDOMAIN }}/metrics
----

You will see a bunch of metrics in the OpenMetrics format:

[source,console]
----
# HELP vendor_memoryPool_usage_bytes Current usage of the memory pool denoted by the 'name' tag
# TYPE vendor_memoryPool_usage_bytes gauge
vendor_memoryPool_usage_bytes{name="PS Survivor Space"} 916920.0
# HELP vendor_memoryPool_usage_bytes Current usage of the memory pool denoted by the 'name' tag
# TYPE vendor_memoryPool_usage_bytes gauge
vendor_memoryPool_usage_bytes{name="PS Old Gen"} 1.489556E7
# HELP vendor_memory_maxNonHeap_bytes Displays the maximum amount of used non-heap memory in bytes.
# TYPE vendor_memory_maxNonHeap_bytes gauge
vendor_memory_maxNonHeap_bytes 4.52984832E8
# HELP vendor_memory_usedNonHeap_bytes Displays the amount of used non-heap memory in bytes.
# TYPE vendor_memory_usedNonHeap_bytes gauge
vendor_memory_usedNonHeap_bytes 5.4685184E7
... and more
----

This is what Prometheus will use to access and index the metrics from our app when we deploy it to the cluster. But first you must tell Prometheus about it!

==== Configure Prometheus ConfigMap

To instruct Prometheus to scrape metrics from our app, we need to create a Kubernetes _ConfigMap_.

On the {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-monitoring[Monitoring Topology View^], click `+Add` on the left, and this time choose *YAML*:

image::add-yaml.png[prometheus, 700]

In the empty box, paste in the following YAML code:

[source,yaml,role="copypaste"]
----
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: {{USER_ID}}-monitoring
data:
  prometheus.yml: >-
    scrape_configs:
      - job_name: 'prometheus'
        static_configs:
        - targets: ['localhost:9090']

      - job_name: 'inventory-quarkus'
        scrape_interval: 10s
        scrape_timeout: 5s
        static_configs:
        - targets: ['inventory.{{USER_ID}}-inventory.svc.cluster.local:8080']
----

And click *Create*.

Config maps hold key-value pairs and in the above command a *prometheus-config* config map is created with *prometheus.yml* as the key and the above content as the value. Whenever a config map is injected into a container, it would appear as a file with the same name as the key, at specified path on the filesystem.

Next, we need to _mount_ this ConfigMap in the filesystem of the Prometheus container so that it can read it. Run this command to alter the Prometheus deployment to mount it:

[source,sh,role="copypaste"]
----
oc set volume -n {{USER_ID}}-monitoring deployment/prometheus --add -t configmap --configmap-name=prometheus-config -m /etc/prometheus/prometheus.yml --sub-path=prometheus.yml && \
oc rollout status -n {{USER_ID}}-monitoring -w deployment/prometheus
----
This will trigger a new deployment of prometheus. Wait for it to finish!

==== 13. Generate some values for the metrics

Now that Prometheus is scraping values from our app, let’s write a loop to call our inventory service multiple times so we can observe the metrics. Do this with the following commands:

[source,sh,role="copypaste"]
----
URL=http://$(oc get route -n {{ USER_ID }}-inventory inventory -o jsonpath={% raw %}"{.spec.host}"{% endraw %})

for i in $(seq 1 600) ; do
  curl -s $URL/services/inventory/165613
  curl -s $URL/services/inventory
  sleep 1
done
----
Leave this loop running (it will end after 600 seconds, or 10 minutes)

We have 3 ways to view the metrics:

. `curl` commands (which you already did)
. Prometheus Queries
. Grafana Dashboards

==== Using Prometheus

Open the http://prometheus-{{USER_ID}}-monitoring.{{ ROUTE_SUBDOMAIN }}[Prometheus UI^] and input `performedChecks` and select the auto-completed value:

image::prometheus-metrics-console.png[metrics_prometheus, 900]

Switch to *Graph* tab:

image::prometheus-metrics-graph.png[metrics_prometheus, 900]

You can play with the values for time and see different data across different time ranges for this metric. There are many other metrics you can query for, and perform quite complex queries using https://prometheus.io/docs/prometheus/latest/querying/basics/[Prom QL^] (Prometheus Query Language).

==== Using Grafana

Open the http://grafana-{{USER_ID}}-monitoring.{{ ROUTE_SUBDOMAIN }}[Grafana UI^].

Select *New Dashboard* to create a new _Dashboard_ to review the metrics.

image::grafana-create-dashboard.png[metrics_grafana, 900]

Click on *Add new panel* to add a new panel with a query:

image::grafana-add-query.png[metrics_grafana, 700]

Type in `performedChecks` in the _Metrics_ field, and choose the first auto-completed value:

image::grafana-add-query-detail.png[metrics_grafana, 700]

Press kbd:[ENTER] while the cursor is in the field, and the values should begin showing up. Choose *Last 15 Minutes* in the drop-down as shown:

image::grafana-add-query-detail2.png[metrics_grafana, 700]

You can fine tune the display, along with the type of graph (bar, line, gauge, etc). Using other options. When done, click the *Save* button, give your new dashboard a name, and click *Save*:

image::grafana-add-query-detail3.png[metrics_grafana, 700]

This is optional, but you can add more Panels if you like, for example: The JVM RSS Value `process_resident_memory_bytes` (set the Visualization to `Gauge` and the Unit in _Field_ tab to `bytes(IEC)` on the _Visualization_, and the title to `Memory` on the _Panel Title_). It could look like:

image::grafana-add-query-detail4.png[metrics_grafana, 700]

You can see more examples of more complex dashboard, and even import them into your own dashboards from the https://grafana.com/grafana/dashboards[Grafana Labs Dashboard community^].

=== Extra Credit: Spring Boot

If you feel up to it, Spring Boot can also expose Metrics which can be collected by Prometheus and displayed with Grafana. To add metrics support to your Catalog service written with Spring Boot, you'll need to:

. Add dependencies for Spring Boot Actuator and Prometheus
. Configure `application-openshift.properties` with config values
. Re-build and Re-deploy the app to OpenShift (in the {{USER_ID}}-catalog project) using commands from previous modules
. Edit the Prometheus _ConfigMap_ to add another scrape job pointing at `catalog-springboot.{{USER_ID}}-catalog.svc.cluster.local:8080`
. Re-deploy Prometheus to pick up the new config
. Attempt to query Prometheus for the Spring Boot metrics(i.e. scrape_duration_seconds)

It is beyond the scope of this lab, but if you're interested, give it a go if you have extra time!

=== Summary

このラボでは、 Jaeger、Prometheus、Grafana を使用してクラウドネイティブアプリケーションを監視する方法を学びました。また、 Quarkus を使用することで、開発者やオペレータとしての観察タスクが容易になることも学びました。これらのテクニックを将来のプロジェクトで使用して、分散型クラウドネイティブアプリケーションを監視することができます。
